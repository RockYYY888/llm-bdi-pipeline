# LTL-BDI Dual-Branch Pipeline

**Comparative Evaluation: Classical Planning vs. LLM-Generated AgentSpeak**

---

## ğŸ¯ Project Overview

A research pipeline that compares two approaches to intelligent agent planning:
- **Branch A (Baseline)**: Classical PDDL planning
- **Branch B (Novel)**: LLM-generated AgentSpeak plan libraries

**Key Innovation**: Generate complete BDI agent plan libraries from LTLf specifications using LLMs, then compare against classical planning.

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies
cd llm-bdi-pipeline-dev
/opt/anaconda3/bin/pip install pyperplan openai python-dotenv
```

### Configuration

```bash
# Create .env file
cp .env.example .env

# Edit .env and add your OpenAI API key
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini
```

### Run Demo

```bash
python src/main.py "Stack block C on block B"
```

**Expected Output**:
```
================================================================================
LTL-BDI PIPELINE - DUAL BRANCH DEMONSTRATION
================================================================================

[STAGE 1] Natural Language -> LTLf Specification
âœ“ LTLf Formula: ['F(on(c, b))']
  Objects: ['b', 'c']

[STAGE 2] LTLf -> PDDL Problem
âœ“ PDDL Problem Generated

[STAGE 3A] BRANCH A: Classical PDDL Planning
âœ“ Classical Plan Generated (2 actions)
  1. pickup(c)
  2. stack(c, b)

[STAGE 3B] BRANCH B: LLM AgentSpeak Generation
âœ“ AgentSpeak Plan Library Generated
  Plans: 17
  Saved to: output/generated_agent.asl

[STAGE 4] Execution & Comparative Evaluation
âœ“ Both branches succeeded

Efficiency:
  Classical Actions: 2
  AgentSpeak Actions: 2
  Efficiency Ratio: 1.00
```

---

## ğŸ“ System Architecture

```
Natural Language Input
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: NL â†’ LTLf               â”‚
â”‚  ltl_parser.py                     â”‚
â”‚  Output: F(on(c,b))                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: LTLf â†’ PDDL             â”‚
â”‚  ltl_to_pddl.py                    â”‚
â”‚  Output: problem.pddl              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
       â”‚           â”‚
       â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRANCH A    â”‚  â”‚  BRANCH B            â”‚
â”‚  Classical   â”‚  â”‚  LLM AgentSpeak      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3A: Classical Planning            â”‚
â”‚  pddl_planner.py                         â”‚
â”‚  Output: [pickup(c), stack(c,b)]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3B: AgentSpeak Generation         â”‚
â”‚  agentspeak_generator.py                 â”‚
â”‚  Output: generated_agent.asl             â”‚
â”‚  (Complete BDI plan library)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: Execution & Comparison         â”‚
â”‚  agentspeak_simulator.py                 â”‚
â”‚  comparative_evaluator.py                â”‚
â”‚                                          â”‚
â”‚  Metrics:                                â”‚
â”‚  - Goal satisfaction                     â”‚
â”‚  - Efficiency (action count)             â”‚
â”‚  - Success rate                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Stage Details

### Stage 1: Natural Language â†’ LTLf

**Input**: `"Stack block C on block B"`

**Output**:
```json
{
  "objects": ["c", "b"],
  "initial_state": [
    {"ontable": ["b"]},
    {"ontable": ["c"]},
    {"clear": ["b"]},
    {"clear": ["c"]},
    {"handempty": []}
  ],
  "formulas": ["F(on(c, b))"]
}
```

**Implementation**: `src/stage1_interpretation/ltl_parser.py`

---

### Stage 2: LTLf â†’ PDDL Problem

**Input**: LTLf specification from Stage 1

**Output**: `problem.pddl`
```pddl
(define (problem stack-blocks)
  (:domain blocksworld)
  (:objects c b - block)
  (:init (ontable c) (ontable b) (clear c) (clear b) (handempty))
  (:goal (and (on c b)))
)
```

**Implementation**: `src/stage2_translation/ltl_to_pddl.py`

---

### Stage 3A: Classical PDDL Planning (Branch A - Baseline)

**Input**: `problem.pddl` + `domain.pddl`

**Output**: Action sequence
```python
[('pickup', ['c']), ('stack', ['c', 'b'])]
```

**Characteristics**:
- âœ… Optimal (minimal actions)
- âœ… Fast execution
- âŒ No failure recovery
- âŒ Brittle to unexpected states

**Implementation**: `src/stage3_codegen/pddl_planner.py` (using pyperplan)

---

### Stage 3B: LLM AgentSpeak Generation (Branch B - Novel)

**Input**: LTLf specification + domain context

**Output**: `generated_agent.asl` (AgentSpeak plan library)

**Example Generated Code**:
```agentspeak
// Main goal from LTLf F formula: F(on(c, b))
+!achieve_on_c_b : true <-
    .print("Starting to achieve on(c, b)");
    !![on(c, b)].

// Declarative goal for on(c, b)
+!![on(c, b)] : on(c, b) <-
    .print("Goal already achieved");
    !verify_success.

// Plan when blocks are clear and on table
+!![on(c, b)] : clear(c) & ontable(c) & clear(b) & handempty <-
    pickup(c);
    +holding(c);
    -handempty;
    stack(c, b);
    -holding(c);
    +handempty;
    +on(c, b).

// Failure handling
-!![on(c, b)] : true <-
    .print("Declarative goal failed, retrying");
    !recover_and_retry.
```

**Characteristics**:
- âœ… Context-adaptive plans
- âœ… Failure recovery strategies
- âœ… Multiple plan options
- âš ï¸ May be sub-optimal

**Implementation**: `src/stage3_codegen/agentspeak_generator.py`

---

### Stage 4: Execution & Comparative Evaluation

**Branch A Execution**: Sequential action execution in blocksworld simulator

**Branch B Execution**: BDI reasoning cycle
1. Goal posting: `achieve_on_c_b`
2. Plan selection: Match trigger and context
3. Action execution: Execute plan body
4. Belief updates: Track state changes

**Comparison Metrics**:
```
âœ“ Both branches succeeded

Efficiency:
  Classical Actions: 2
  AgentSpeak Actions: 2
  Efficiency Ratio: 1.00

Robustness:
  Classical Failure Recovery: False
  AgentSpeak Failure Plans: False
```

**Implementation**:
- `src/stage4_execution/blocksworld_simulator.py` - Environment
- `src/stage4_execution/agentspeak_simulator.py` - BDI execution
- `src/stage4_execution/comparative_evaluator.py` - Metrics

---

## ğŸ› ï¸ Implementation Status

### âœ… Completed Components

**Core Pipeline**:
- [x] Stage 1: NL â†’ LTLf parser
- [x] Stage 2: LTLf â†’ PDDL converter
- [x] Stage 3A: Classical PDDL planner
- [x] Stage 3B: AgentSpeak generator
- [x] Stage 4: Execution & comparison

**AgentSpeak Simulator**:
- [x] Multi-line plan parsing
- [x] Declarative goal support (`+!!`)
- [x] Variable unification
- [x] Belief format conversion (`ontable` â†” `on(X,table)`)
- [x] Context checking with negation
- [x] Primitive action execution
- [x] BDI reasoning cycle

**Pipeline Infrastructure**:
- [x] Configuration management (.env)
- [x] Logging system
- [x] Dual-branch orchestration
- [x] Blocksworld environment simulator

### ğŸ”§ Known Limitations (MVP Scope)

**L1: Limited LTLf Temporal Verification**
- **Impact**: Can only verify `F(Ï†)` (Eventually) goals, not `G(Ï†)` (Always), `X(Ï†)` (Next), or `Ï† U Ïˆ` (Until)
- **Current Implementation**: Checks if goal predicate exists in final state (no temporal trace verification)
- **Code** (`comparative_evaluator.py`):
  ```python
  def _check_ltl_satisfaction(self, final_state, ltl_goal):
      if ltl_goal.startswith('F(') and ltl_goal.endswith(')'):
          goal_predicate = ltl_goal[2:-1]  # Extract Ï† from F(Ï†)
          return goal_predicate in final_state
      return True  # MVP: can't verify other formulas
  ```
- **Future Work**: Integrate proper LTLf verification library (e.g., spot, pyLTL)
- **Priority**: LOW (acceptable for research prototype)

**L2: Simplified AgentSpeak Subset**
- **Supported**: Achievement goals (`+!goal`), declarative goals (`+!![state]`), context guards, belief updates (`+/-belief`)
- **Not Supported**:
  - Complex annotations
  - Internal actions beyond `.print()`
  - Event handling and intentions
  - Strong negation
- **Workaround**: Generator produces simplified AgentSpeak code within supported subset
- **Priority**: MEDIUM

**L3: Manual Belief Revision**
- **Impact**: Belief updates after actions must be explicitly coded in AgentSpeak plans
- **Example**: After `pickup(X)`, must manually add `+holding(X); -handempty; -clear(X)`
- **Workaround**: Generator includes explicit +/- belief updates in all action plans
- **Priority**: LOW (manual specification acceptable for MVP)

**L4: Single Agent Only**
- **Impact**: No multi-agent coordination or communication
- **Scope**: Intentionally out of scope for this research
- **Priority**: N/A

---

## ğŸ“Š Test Results

### Simple Stack Scenario: "Stack block C on block B"

**Test Status**: âœ… **PASSING**

```
BRANCH A: Classical PDDL Planning
  Success: True
  Actions: 2 (pickup, stack)
  Final State: on(c,b) achieved

BRANCH B: LLM AgentSpeak
  Success: True
  Actions: 2 (pickup, stack)
  Final State: on(c,b) achieved

Comparison:
  Efficiency Ratio: 1.00 (equal)
  Both branches succeeded
```

### Additional Scenarios

| Scenario | Classical | AgentSpeak | Status |
|----------|-----------|------------|--------|
| Simple stack (C on B) | âœ… Pass | âœ… Pass | **VERIFIED** |
| Three-block tower | â“ | â“ | Not tested |
| Block rearrangement | â“ | â“ | Not tested |
| Parallel stacks | â“ | â“ | Not tested |

---

## ğŸ“ Project Structure

```
llm-bdi-pipeline-dev/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ stage1_interpretation/
â”‚   â”‚   â””â”€â”€ ltl_parser.py              # NL â†’ LTLf
â”‚   â”œâ”€â”€ stage2_translation/
â”‚   â”‚   â””â”€â”€ ltl_to_pddl.py            # LTLf â†’ PDDL
â”‚   â”œâ”€â”€ stage3_codegen/
â”‚   â”‚   â”œâ”€â”€ pddl_planner.py           # Classical planner
â”‚   â”‚   â””â”€â”€ agentspeak_generator.py   # LLM AgentSpeak gen
â”‚   â”œâ”€â”€ stage4_execution/
â”‚   â”‚   â”œâ”€â”€ blocksworld_simulator.py  # Environment
â”‚   â”‚   â”œâ”€â”€ agentspeak_simulator.py   # BDI execution
â”‚   â”‚   â””â”€â”€ comparative_evaluator.py  # Metrics
â”‚   â”œâ”€â”€ dual_branch_pipeline.py       # Pipeline orchestrator
â”‚   â”œâ”€â”€ config.py                      # Configuration
â”‚   â”œâ”€â”€ pipeline_logger.py             # Logging
â”‚   â””â”€â”€ main.py                        # Entry point
â”œâ”€â”€ domains/
â”‚   â””â”€â”€ blocksworld/
â”‚       â””â”€â”€ domain.pddl                # PDDL domain (given)
â”œâ”€â”€ output/
â”‚   â””â”€â”€ generated_agent.asl            # Generated plans
â””â”€â”€ .env                               # API keys (gitignored)
```

---

## ğŸ”‘ Critical Implementation Fixes

Seven critical bugs were identified and fixed during implementation. Each fix was essential for the pipeline to work correctly.

### Fix #1: Initial State Format Conversion

**Problem**: LTL parser generates `ontable(X)` but blocksworld simulator expects `on(X, table)`

**Impact**: Classical planner failed with precondition errors

**Solution** (`dual_branch_pipeline.py:236-246`):
```python
# Convert dict-based initial_state to string-based beliefs
beliefs = []
for pred_dict in ltl_spec.initial_state:
    for pred_name, args in pred_dict.items():
        if pred_name == 'ontable' and args:
            # Convert ontable(X) to on(X, table)
            for block in args:
                beliefs.append(f"on({block}, table)")
        elif args:
            beliefs.append(f"{pred_name}({', '.join(args)})")
        else:
            beliefs.append(pred_name)
```

### Fix #2: Multi-Line Plan Parsing

**Problem**: Generated AgentSpeak code spans multiple lines but parser expected single-line plans

**Impact**: 0 plans were parsed successfully

**Solution** (`agentspeak_simulator.py:41-76`):
```python
def _parse_asl(self, asl_code: str):
    """Parse AgentSpeak code - handles multi-line plans"""
    current_plan_text = ""
    for line in lines:
        line = line.strip()
        if not line or (line.startswith('//') and not current_plan_text):
            continue

        if line.startswith(('+!', '-!')):
            if current_plan_text:
                self._parse_single_plan(current_plan_text)
            current_plan_text = line
        elif current_plan_text:
            current_plan_text += " " + line

        if current_plan_text and current_plan_text.rstrip().endswith('.'):
            self._parse_single_plan(current_plan_text)
            current_plan_text = ""
```

### Fix #3: Declarative Goal Support

**Problem**: Parser couldn't handle `+!![goal]` syntax for declarative goals

**Impact**: Generated plans with declarative goals were not recognized

**Solution** (`agentspeak_simulator.py:82`):
```python
# Pattern handles both +! (achievement) and +!! (declarative)
plan_pattern = r'(\+!!?[\w\(\),\s\[\]_]+)\s*:\s*([^<]*)\s*<-\s*(.+)\.'
```

### Fix #4: Variable Unification

**Problem**: Plans with variables `stack(X,Y)` couldn't match goals `stack(c,b)`

**Impact**: No plans were found as "applicable" during execution

**Solution** (`agentspeak_simulator.py:183-224`):
```python
def _unify_goal(self, pattern: str, goal: str) -> bool:
    """Check if pattern matches goal with variable unification"""
    pattern_match = re.match(r'(\w+)\((.*?)\)', pattern)
    goal_match = re.match(r'(\w+)\((.*?)\)', goal)

    if not pattern_match or not goal_match:
        return False

    pattern_pred, pattern_args_str = pattern_match.groups()
    goal_pred, goal_args_str = goal_match.groups()

    # Predicates must match
    if pattern_pred != goal_pred:
        return False

    # Parse and check arguments
    pattern_args = [a.strip() for a in pattern_args_str.split(',') if a.strip()]
    goal_args = [a.strip() for a in goal_args_str.split(',') if a.strip()]

    if len(pattern_args) != len(goal_args):
        return False

    for p_arg, g_arg in zip(pattern_args, goal_args):
        # Uppercase = variable (matches anything)
        if p_arg and p_arg[0].isupper():
            continue
        # Lowercase = constant (must match exactly)
        elif p_arg == g_arg:
            continue
        else:
            return False

    return True
```

### Fix #5: Belief Format Bidirectional Conversion

**Problem**: Generated code checks `ontable(c)` but beliefs contain `on(c,table)` (with/without space)

**Impact**: All context checks failed, no plans were applicable

**Solution** (`agentspeak_simulator.py:128-150`):
```python
def _belief_exists(self, condition: str) -> bool:
    """Check if belief exists, handling ontable(X) <-> on(X,table) conversion"""
    # Direct match first
    if condition in self.beliefs:
        return True

    # Convert ontable(X) to on(X, table) - try both with and without space
    match = re.match(r'ontable\((\w+)\)', condition)
    if match:
        block = match.group(1)
        return (f"on({block}, table)" in self.beliefs or
                f"on({block},table)" in self.beliefs)

    # Convert on(X, table) to ontable(X)
    match = re.match(r'on\((\w+),\s*table\)', condition)
    if match:
        block = match.group(1)
        return f"ontable({block})" in self.beliefs

    return False
```

### Fix #6: Declarative Goal Early Satisfaction

**Problem**: Declarative goals `!!goal` were not distinguished from achievement goals `!goal`

**Impact**: Redundant plan execution even when goal already satisfied

**Solution** (`agentspeak_simulator.py:299-308`):
```python
def _achieve_goal(self, goal: str) -> bool:
    """Achieve a goal using BDI reasoning cycle"""
    # For declarative goals with brackets, check if already satisfied
    if goal.startswith('[') and goal.endswith(']'):
        goal_condition = goal.strip('[]')
        if self._belief_exists(goal_condition):
            return True  # Already satisfied!

    # Otherwise, select and execute plan
    plan = self._select_plan(goal)
    ...
```

### Fix #7: Bracket Normalization

**Problem**: Goal `[on(c,b)]` didn't match trigger `on(c,b)` in plan selection

**Impact**: Valid plans were not selected

**Solution** (`agentspeak_simulator.py:152-181`):
```python
def _select_plan(self, goal: str) -> Optional[AgentSpeakPlan]:
    """Select applicable plan for goal with variable unification"""
    # Strip brackets from goal if present (declarative goals)
    goal_normalized = goal.strip('[]')

    for plan in self.plans:
        # Extract goal from trigger and remove brackets
        trigger_goal = plan.trigger.replace('+!!', '').replace('+!', '').strip()
        trigger_goal = trigger_goal.strip('[]')

        # Compare normalized forms
        if trigger_goal == goal_normalized:
            if self._check_context(plan.context):
                applicable.append(plan)
        elif self._unify_goal(trigger_goal, goal_normalized):
            if self._check_context(plan.context):
                applicable.append(plan)

    return applicable[0] if applicable else None
```

---

## âš ï¸ Known Issues and Incomplete Features

**IMPORTANT**: The following issues were discovered through comprehensive testing. The pipeline works correctly for **simple single-goal scenarios** (e.g., "Stack block C on block B") but has limitations for more complex cases.

### Issue 1: Multiple LTLf Goals Not Fully Supported âš ï¸ MAJOR

**Problem**: When natural language describes multiple goals (e.g., "Build a tower with A on B on C"), the pipeline generates multiple LTLf formulas but only processes the first one.

**Test Case**:
```bash
Input: "Build a tower with block A on block B on block C"
LTLf Generated: ['F(on(a, b))', 'F(on(b, c))']  # Two goals!
```

**What Happens**:
1. **Stage 2 (PDDL Generation)**: LLM may generate incomplete PDDL goal (observed: `(on a b` without closing paren and missing second goal)
2. **Stage 3B (AgentSpeak)**: `_extract_agentspeak_goal()` only extracts first formula â†’ creates `achieve_on_a_b`, ignores `F(on(b,c))`
3. **Stage 4 (Verification)**: `_check_ltl_satisfaction()` only checks first formula

**Impact**:
- âœ… Classical planner: May still work if PDDL LLM generates complete conjunctive goal
- âŒ AgentSpeak execution: Only achieves first sub-goal, ignores others
- âŒ Goal verification: Reports "Goal Satisfied: False" even when first goal is met

**Affected Code**:
- `dual_branch_pipeline.py:277-292` - `_extract_agentspeak_goal()` only matches one `F(on(X,Y))`
- `comparative_evaluator.py:148-163` - `_check_ltl_satisfaction()` only checks one goal
- `dual_branch_pipeline.py:251-262` - Passes only `formulas_string_list[0]` to evaluator

**Status**: ğŸ”´ **INCOMPLETE** - Multi-goal support not implemented

---

### Issue 2: LTLf Goal Verification Space Mismatch âš ï¸ MODERATE â†’ âœ… FIXED

**Problem**: Goal verification fails due to whitespace inconsistency between extracted goal and final state format.

**Root Cause**:
```python
# comparative_evaluator.py:156 (OLD CODE)
goal_predicate = ltl_goal[2:-1]  # Extracts "on(a, b)" with space
# But final_state contains: "on(a,b)" (no space)
return goal_predicate in final_state  # Always False!
```

**Test Evidence**:
```
Test: "Stack block C on block B"
LTLf Goal: F(on(c, b))          # Space after comma
Extracted: "on(c, b)"            # Space preserved
Final State: ['on(c,b)', ...]   # No space
Result: Goal Satisfied: False   # WRONG! Goal was actually achieved
```

**Fix Applied** (Phase 1.1):
Normalize spaces in both goal and state before comparison:
```python
# comparative_evaluator.py:148-170 (NEW CODE)
goal_normalized = goal_predicate.replace(' ', '')  # Remove spaces
for state_pred in final_state:
    if state_pred.replace(' ', '') == goal_normalized:
        return True
```

**Code Location**: `src/stage4_execution/comparative_evaluator.py:148-170`

**Status**: âœ… **FIXED** - Space normalization added

---

### Issue 3: Hardcoded Single-Goal Assumptions ğŸ”’ LIMITATION

**Problem**: Multiple components assume exactly one LTLf goal.

**Hardcoded Logic**:

1. **Goal Extraction** (`dual_branch_pipeline.py:277-292`):
   ```python
   def _extract_agentspeak_goal(self, ltl_formula: str):
       # Match F(on(X, Y)) - ONLY ONE!
       match = re.match(r'F\(on\((\w+),\s*(\w+)\)\)', ltl_formula)
   ```

2. **Goal Passing** (`dual_branch_pipeline.py:253`):
   ```python
   agentspeak_goal = self._extract_agentspeak_goal(formulas_string_list[0])  # [0]!
   ```

3. **Verification** (`comparative_evaluator.py:180`):
   ```python
   report.append(f"\nLTLf Goal: {self.results['ltl_goal']}")  # Singular!
   ```

**Impact**:
- Works for: Simple scenarios with one goal ("Stack C on B")
- Fails for: Complex scenarios with multiple goals ("Build tower A-B-C")

**Status**: ğŸ”’ **BY DESIGN** - MVP limitation

---

### Issue 4: No Conjunctive or Sequential Goal Support ğŸ”’ LIMITATION

**Problem**: Cannot handle:
- Conjunctive goals: `F(on(a,b) & on(b,c))` - "A on B AND B on C simultaneously"
- Sequential goals: `F(on(b,c)) & F(F(on(a,b)))` - "First B on C, then A on B"
- Complex temporal: `G(holding(X) -> F(ontable(X)))` - "Whatever you pick up must eventually be put down"

**Current Support**: Only `F(Ï†)` where Ï† is a single atomic predicate

**Status**: ğŸ”’ **OUT OF SCOPE** - Future work

---

### Issue 5: PDDL Goal Generation Relies on LLM Quality âš ï¸ MODERATE â†’ âœ… FIXED

**Problem**: Stage 2 uses LLM to generate PDDL, which may produce incomplete or incorrect goals for complex inputs.

**Observed**:
```
Input: "Build tower A on B on C"
LTLf: ['F(on(a, b))', 'F(on(b, c))']
PDDL Goal (generated): "(on a b"      # Incomplete! Missing ) and second goal
```

**Impact**:
- Classical planning may fail or solve wrong problem
- No validation of LLM-generated PDDL

**Fix Applied** (Phase 1.2):
Added `validate_pddl_syntax()` function in `ltl_to_pddl.py` that checks:
- âœ… Balanced parentheses (open count == close count)
- âœ… Required sections: `:domain`, `:objects`, `:init`, `:goal`
- âœ… Goal section has content (not empty)
- âœ… Objects section has content
- âœ… Must start with `(define (problem`

**Code Location**: `src/stage2_translation/ltl_to_pddl.py:25-78` (validation function) and `:249-256` (integration)

**Status**: âœ… **FIXED** - PDDL syntax validation now active

---

### Issue 6: Limited Blocksworld Initial States ğŸ”’ LIMITATION

**Current**: All blocks start `on(table)` and `clear`

**Not Supported**:
- Blocks already stacked in initial state
- Blocks held in hand initially
- Complex configurations

**Why**: LTL parser prompt assumes "blocks on table" initial configuration

**Status**: ğŸ”’ **BY DESIGN** - Simplifying assumption for MVP

---

## ğŸ—ï¸ Architecture Analysis: Integration vs Comparison

### Proposed Integration Architecture (Evaluated)

User proposed this unified pipeline architecture:
```
Natural Language Instruction
         â†“
[LTLf Goal Specification]
         â†“
[FOND Planning with LTLf Goals]
         â†“
[Policy (State â†’ Action mapping)]
         â†“
[AgentSpeak Execution]
         â†“
[Runtime LTLf Monitoring]
```

### Current Dual-Branch Comparison Architecture

```
Natural Language
       â†“
    [LTLf]
       â†“
    [PDDL]
       â†“
    â”Œâ”€â”€â”´â”€â”€â”
    â–¼     â–¼
Branch A  Branch B
Classical  LLM
Planning  AgentSpeak
    â†“     â†“
[Comparison]
```

### Key Differences

| Aspect | Proposed (Integration) | Current (Comparison) |
|--------|----------------------|---------------------|
| **Planner** | FOND (non-deterministic) | pyperplan (deterministic) |
| **Output** | Policy (stateâ†’action map) | Plan (linear sequence) |
| **Relationship** | FOND guides AgentSpeak | Independent execution |
| **Research Q** | "How can classical enhance LLM?" | "How does LLM compare to classical?" |
| **Goal Dependencies** | âœ… FOND handles automatically | âŒ Current issue (see tower example) |
| **Robustness** | âœ… Policy covers multiple states | âš ï¸ Plan is single trajectory |
| **Runtime Monitoring** | âœ… Continuous LTLf checking | âš ï¸ End-state verification only |

### Analysis & Decision

**Advantages of Integration Architecture:**
1. âœ… **Solves goal ordering problem**: FOND policy naturally handles dependencies (Bâ†’C before Aâ†’B)
2. âœ… **State-aware execution**: Policy provides actions for ANY reachable state
3. âœ… **Runtime verification**: Continuous LTLf monitoring vs end-state only
4. âœ… **Production-ready**: Better for real-world BDI systems

**Disadvantages:**
1. âŒ **Changes research focus**: From comparison to integration
2. âŒ **Loses dual-branch insights**: Can't compare LLM vs classical separately
3. âŒ **Requires FOND planner**: Not currently implemented (only pyperplan)
4. âŒ **Policyâ†’AgentSpeak translation**: Need new conversion logic

### Recommended Approach: **KEEP CURRENT + ADD INTEGRATION AS FUTURE WORK**

**Rationale:**
- **Current dual-branch architecture serves core research goal**: Comparative evaluation
- **Integration architecture is FUTURE ENHANCEMENT**, not replacement
- **Goal ordering issue discovered through comparison** - this is valuable research insight!
- **Can add FOND-guided branch later** as Branch C without disrupting A vs B comparison

**Implementation Priority:**
1. âœ… **Phase 1 (DONE)**: Fix current architecture issues (verification, validation, multi-goal)
2. ğŸ“‹ **Phase 2 (NEXT)**: Enhance current comparison (better goal ordering, PDDL multi-goal)
3. ğŸ”® **Phase 3 (FUTURE)**: Add FOND-guided AgentSpeak as Branch C for three-way comparison

**Current Status**: Dual-branch architecture is appropriate for comparative research. Integration architecture documented as future enhancement.

---

## ğŸ”§ Recent Fixes (Phase 1 MVP Completion)

### âœ… Fix 1: Goal Verification Space Normalization (Issue 2)
**Problem**: Goal verification failed due to `"on(c, b)"` vs `"on(c,b)"` mismatch
**Solution**: Added space normalization in `comparative_evaluator.py:148-170`
**Result**: âœ“ Goal verification now correctly reports True for achieved goals
**Code Location**: `src/stage4_execution/comparative_evaluator.py:148-170`

### âœ… Fix 2: PDDL Syntax Validation (Issue 5)
**Problem**: No validation of LLM-generated PDDL, could produce invalid syntax
**Solution**: Added `validate_pddl_syntax()` function checking:
- Balanced parentheses
- Required sections (`:domain`, `:objects`, `:init`, `:goal`)
- Non-empty goal and objects sections

**Result**: âœ“ Invalid PDDL now caught with clear error messages
**Code Location**: `src/stage2_translation/ltl_to_pddl.py:25-78` (validator) and `:249-256` (integration)

### âœ… Fix 3: Multi-Goal Verification Support (Issue 1 - Partial)
**Problem**: Verification only checked first LTLf formula when multiple goals existed
**Solution**: Updated `_compare_results()` to:
- Accept `List[str]` or `str` for `ltl_goal` parameter
- Check ALL goals individually
- Report detailed per-goal satisfaction status
- Overall satisfaction requires ALL goals met

**Result**: âœ“ Multi-goal verification now works correctly
**Example Output**:
```
LTLf Goals (2):
  1. F(on(a, b))
  2. F(on(b, c))

Detailed Goal Verification:
  âœ“ F(on(a, b))
  âœ— F(on(b, c))
```
**Code Locations**:
- `src/stage4_execution/comparative_evaluator.py:98-145` (verification logic)
- `src/stage4_execution/comparative_evaluator.py:210-255` (report generation)
- `src/dual_branch_pipeline.py:254-265` (pass all formulas)

### âš ï¸ Remaining Limitation: Goal Ordering Dependencies
**Discovery**: Multi-goal tower building ("Build tower A on B on C") reveals **goal dependency** issue:
- **Classical planner**: Correctly determines order (stack B on C first, then A on B) âœ“
- **AgentSpeak**: Executes goals in given order, making second goal unreachable âœ—
- **Root Cause**: No dependency analysis - AgentSpeak executes `!achieve_on_a_b; !achieve_on_b_c`, but after stacking A on B, B is no longer clear

**Example**:
```
Goals: ["F(on(a,b))", "F(on(b,c))"]
Naive Order: Aâ†’B then Bâ†’C (FAILS - B not clear after A stacked)
Correct Order: Bâ†’C then Aâ†’B (WORKS)
```

**Status**: This requires either:
1. Goal dependency analysis & reordering
2. More sophisticated LLM prompt to generate dependency-aware ordering
3. Integration with FOND planner for state-aware goal sequencing

---

## âœ… What Actually Works (Verified)

**Fully Functional**:
1. âœ… Simple single-goal stacking: "Stack block C on block B"
2. âœ… Classical PDDL planning for single goals
3. âœ… AgentSpeak generation and parsing for single goals
4. âœ… BDI execution with declarative goals
5. âœ… All 7 critical fixes (multi-line parsing, variable unification, belief conversion, etc.)
6. âœ… **NEW**: Multi-goal verification with detailed per-goal reporting
7. âœ… **NEW**: PDDL syntax validation

**Partially Functional**:
8. âš ï¸ Multi-goal scenarios:
   - Classical planner: May work (depends on LLM goal generation and planner capabilities)
   - AgentSpeak: Achieves goals in sequence but fails when dependencies exist
   - **Root Cause**: No goal dependency analysis

**Not Implemented**:
9. âŒ Goal dependency analysis and reordering
10. âŒ Conjunctive goals (simultaneous requirements)
11. âŒ Sequential/temporal goals with explicit ordering
12. âŒ Complex LTL operators (G, X, U)

---

## ğŸ“ Research Context

**Project**: Final Year Project (FYP)
**Institution**: University of Nottingham Ningbo China
**Author**: Yiwei LI (20513831)
**Supervisor**: Yuan Yao

### Research Questions (Updated with Test Results)

**RQ1**: Can LLMs generate correct AgentSpeak plan libraries from LTLf specifications?
- âœ… Syntax: Generated code parses successfully
- âœ… Semantics: Plans execute correctly for **single-goal** blocksworld scenarios
- âš ï¸ **Limitation**: Only supports single `F(on(X,Y))` goals currently

**RQ2**: How do LLM-generated plans compare to classical planning?
- âœ… Efficiency: Equal action count for simple scenarios (tested: "Stack C on B")
- âš ï¸ **Issue Found**: Multi-goal scenarios show discrepancy - classical may solve full problem, AgentSpeak only partial

**RQ3**: Are LLM-generated plans more robust to failures?
- â“ Pending: Failure injection tests needed

**RQ4**: Can LLM plans handle novel situations?
- â“ Pending: Unseen state tests needed
- âš ï¸ **Current**: Limited to single-goal scenarios

### Key Contributions

1. **Dual-Branch Comparative Framework**: First implementation comparing classical planning with LLM-generated BDI plans
2. **LTLf-to-AgentSpeak Pipeline**: Novel approach using temporal logic as intermediate representation
3. **Working BDI Simulator**: Pure Python implementation of AgentSpeak subset (no Jason dependency)
4. **Comprehensive Documentation**: All implementation challenges, fixes, and **limitations** fully documented

---

## ğŸ“ License

Academic research project - University of Nottingham Ningbo China

---

## ğŸ“š References

- **BDI Architecture**: Bordini et al. (2007) - Programming Multi-Agent Systems in AgentSpeak using Jason
- **LTLf**: De Giacomo & Vardi (2013) - Linear Temporal Logic on Finite Traces
- **PDDL Planning**: Geffner & Bonet (2013) - A Concise Introduction to Models and Methods for Automated Planning
